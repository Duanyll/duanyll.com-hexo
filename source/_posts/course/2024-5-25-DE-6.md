---
title: 微分方程数值解作业 6
tags:
  - 微分方程
tikzjax: true
---

## Problem 1

![](https://cdn.duanyll.com/img/20240525164212.png)

![](https://cdn.duanyll.com/img/20240525164402.png)

### Question (a)

The equation to solve is 

$$
u_{xx}+u_{yy}+\alpha u_x+\beta u_y+\gamma u=0.
$$

Use a rectangular grid

$$
\begin{aligned}
    x_i&=ih,~i=0,1,\cdots,N+1,\\
    y_j&=jk,~j=0,1,\cdots,M+1,\\
    u_{ij}&=u(x_i,y_j),\\
\end{aligned}
$$

and the central difference scheme for first and second order derivatives

$$
\begin{aligned}
    \frac{1}{h^2}(u(x_{i+1},y_j)-2u(x_i,y_j)+u(x_{i-1},y_j))+\frac{1}{k^2}(u(x_i,y_{j+1})-2u(x_i,y_j)+u(x_i,y_{j-1}))&\\
    +\frac{\alpha}{2h}(u(x_{i+1},y_j)-u(x_{i-1},y_j))+\frac{\beta}{2k}(u(x_i,y_{j+1})-u(x_i,y_{j-1}))+\gamma u(x_i,y_j)+\tau_{ij}&=0,
\end{aligned}
$$

where $\tau_{ij}=O(h^2+k^2)$ is the truncation error. Dropping the error term and rearranging the equation, we have

$$
\begin{aligned}
    -\frac{2+\alpha h}{2h^2}u_{i+1,j}+\left(\frac{2}{h^2}+\frac{2}{k^2}-\gamma\right)u_{ij}-\frac{2-\alpha h}{2h^2}u_{i-1,j}&\\
    -\frac{2+\beta k}{2k^2}u_{i,j+1}-\frac{2-\beta k}{2k^2}u_{i,j-1}&=0,
\end{aligned}
$$
    
where $i=1,2,\cdots,N$ and $j=1,2,\cdots,M$. Consider the boundary conditions described as 

![](https://cdn.duanyll.com/img/20240525205836.png)

The boundary conditions can be written as

$$
\begin{aligned}
    u_{0,j}&=0,&j=1,2,\cdots,M,\\
    u_{N+1,j}&=0,&j=1,2,\cdots,M,\\
    u_{i,0}&=0,&i=1,2,\cdots,N,\\
    u_{i,M+1}&=g(x_i),&i=1,2,\cdots,N.
\end{aligned}
$$

FDEs at the top row (where $j=M$) transform to

$$
    -\frac{2+\alpha h}{2h^2}u_{i+1,j}+\left(\frac{2}{h^2}+\frac{2}{k^2}-\gamma\right)u_{ij}-\frac{2-\alpha h}{2h^2}u_{i-1,j}-\frac{2-\beta k}{2k^2}u_{i,j-1}=\frac{2+\beta k}{2k^2}g_i.
$$

Let 

$$
v_l=u_{ij},~l=(j-1)N+i,
$$

then the equation can be written as

$$
-\frac{2+\alpha h}{2h^2}v_{l+1}+\left(\frac{2}{h^2}+\frac{2}{k^2}-\gamma\right)v_l-\frac{2-\alpha h}{2h^2}v_{l-1}-\frac{2+\beta k}{2k^2}v_{l+N}-\frac{2-\beta k}{2k^2}v_{l-N}=0.
$$

where $l=1,2,\cdots,NM$. The above equation can be written in matrix form

$$
\mathbf{A}\mathbf{v}=\mathbf{b},
$$

where $\mathbf{v}=(v_1,v_2,\cdots,v_{NM})^T$ and $\mathbf{A}$ is a $(NM)\times(NM)$ matrix. $\mathbf{A}$ has the following structure

$$
\mathbf{A}=\begin{bmatrix}
    \mathbf{T} & \mathbf{D}_u & \mathbf{0} & \cdots & \mathbf{0}\\
    \mathbf{D}_l & \mathbf{T} & \mathbf{D}_u & \cdots & \mathbf{0}\\
    \mathbf{0} & \mathbf{D}_l & \mathbf{T} & \cdots & \mathbf{0}\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    \mathbf{0} & \mathbf{0} & \mathbf{0} & \cdots & \mathbf{T}
\end{bmatrix},
$$

where $\mathbf{T}$ is a $N\times N$ tridiagonal matrix

$$
\mathbf{T}=\begin{bmatrix}
    \frac{2}{h^2}+\frac{2}{k^2}-\gamma & -\frac{2+\alpha h}{2h^2} & 0 & \cdots & 0\\
    -\frac{2-\alpha h}{2h^2} & \frac{2}{h^2}+\frac{2}{k^2}-\gamma & -\frac{2+\alpha h}{2h^2} & \cdots & 0\\
    0 & -\frac{2-\alpha h}{2h^2} & \frac{2}{h^2}+\frac{2}{k^2}-\gamma & \cdots & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \cdots & \frac{2}{h^2}+\frac{2}{k^2}-\gamma
\end{bmatrix},
$$

and $\mathbf{D}_u$ and $\mathbf{D}_l$ are $N\times N$ diagonal matrices

$$
\mathbf{D}_u=-\frac{2+\beta k}{2k^2}\mathbf{I},~\mathbf{D}_l=-\frac{2-\beta k}{2k^2}\mathbf{I}.
$$

$\mathbf{b}$ is a $(NM)\times1$ vector

$$
\mathbf{b}=\left[0,\cdots,0,\frac{2+\beta k}{2k^2}g_1,\cdots,\frac{2+\beta k}{2k^2}g_N\right]^\top
$$

It is easy to see that $\mathbf{A}$ and $\mathbf{b}$ can be reduced to those in (6.20) when $\alpha=\beta=\gamma=0$.

### Question (b)

With $\alpha=\beta=0$,

$$
\mathbf{T}=\begin{bmatrix}
    \frac{2}{h^2}+\frac{2}{k^2}-\gamma & -\frac{1}{h^2} & 0 & \cdots & 0\\
    -\frac{1}{h^2} & \frac{2}{h^2}+\frac{2}{k^2}-\gamma & -\frac{1}{h^2} & \cdots & 0\\
    0 & -\frac{1}{h^2} & \frac{2}{h^2}+\frac{2}{k^2}-\gamma & \cdots & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \cdots & \frac{2}{h^2}+\frac{2}{k^2}-\gamma
\end{bmatrix},
$$

and

$$
\mathbf{D}_u=\mathbf{D}_l=-\frac{1}{k^2}\mathbf{I}.
$$

To use the conjugate gradient method, $\mathbf{A}$ must be symmetric and positive definite. The symmetric property is obvious in this case. Then we use Test 1 in 6.2.2 to derive a necessary condition for $\mathbf{A}$ to be positive definite. The condition is

$$
\frac{2}{h^2}+\frac{2}{k^2}-\gamma>0\implies\gamma<\frac{2}{h^2}+\frac{2}{k^2}.
$$

And derive a sufficient condition for $\mathbf{A}$ using Test 3. 

1. $r_i\leq a_{ii}\implies\gamma\leq 0$.
2. $a_{ii}>0\implies\gamma<\frac{2}{k^2}+\frac{2}{h^2}$, covered by the first condition.
3. The first row of $\mathbf{A}$ satifies $r_i<a_{ii}$ when the first condition is satisfied.
4. $A$ is irreducible, since the directed graph of $A$ is equivalent to the grid graph, which is connected.

The test suggests that $\gamma\leq 0$ is a sufficient condition for $\mathbf{A}$ to be positive definite.

Using the same test, we can discover that 

$$
\gamma\geq\frac{2}{h^2}+\frac{2}{k^2}
$$

is a sufficient condition for $-\mathbf{A}$ to be positive definite, which also allows the use of the conjugate gradient method.

### Question (c)

The symmetric condition requires $\alpha=\beta=0$, and then with $\gamma=0$, the matrix $\mathbf{A}$ falls back to that in (6.20), which is proved to be positive definite. Therefore the necessary and sufficient condition to use the conjugate gradient method is $\alpha=\beta=0$.

### Question (d)

Combining the results from (b) and (c), we can find a sufficient condition for the utilization of the conjugate gradient method is

$$
\alpha=\beta=0,~\left(\gamma\leq 0\ \text{or}\ \gamma\geq\frac{2}{h^2}+\frac{2}{k^2}\right).
$$

## Problem 2

![](https://cdn.duanyll.com/img/20240525164256.png)

![](https://cdn.duanyll.com/img/20240525164420.png)

### Question (a)

Equation (6.17)

$$
-\lambda^2 u_{i+1,j}+2(1+\lambda^2)u_{ij}-\lambda^2 u_{i-1,j}-u_{i,j+1}-u_{i,j-1}=0
$$

for $i=1,2,\cdots,N$ and $j=1,2,\cdots,M$. Use centered difference at $j=0$ to handle the bottom boundary condition

$$
\frac{1}{2k}(u_{i,1}-u_{i,-1})=g_i\implies u_{i,-1}=u_{i,1}-2kg_i.
$$

The FDEs for $j=0$ are

$$
-\lambda^2 u_{i+1,0}+2(1+\lambda^2)u_{i,0}-\lambda^2 u_{i-1,0}-u_{i,1}-u_{i,-1}=0.
$$

With the boundary condition $u_{i,-1}=u_{i,1}$, the above equation can be simplified to

$$
-\lambda^2 u_{i+1,0}+2(1+\lambda^2)u_{i,0}-\lambda^2 u_{i-1,0}-2u_{i,1}=-2kg_i.
$$

Let 

$$
v_l=u_{ij},~l=jN+i,
$$

we can express the above FDE system as 

$$
\mathbf{A}\mathbf{v}=\mathbf{b},
$$

where $\mathbf{v}\in\R^{(N+1)M}$ is the vectorized form of $u_{ij}$. $\mathbf{A}\in\R^{(N+1)M\times(N+1)M}$ has the following structure

$$
\mathbf{A}=\begin{bmatrix}
    \mathbf{T} & -2\mathbf{I} & \mathbf{0} & \mathbf{0} & \cdots & \mathbf{0}\\
    -\mathbf{I} & \mathbf{T} & -\mathbf{I} & \mathbf{0} & \cdots & \mathbf{0}\\
    \mathbf{0} & -\mathbf{I} & \mathbf{T} & -\mathbf{I} & \cdots & \mathbf{0}\\
    \mathbf{0} & \mathbf{0} & -\mathbf{I} & \mathbf{T} & \cdots & \mathbf{0}\\
    \vdots & \vdots & \vdots & \vdots & \ddots & \vdots\\
    \mathbf{0} & \mathbf{0} & \mathbf{0} & \mathbf{0} & \cdots & \mathbf{T}
\end{bmatrix},
$$

$\mathbf{T}\in\R^{N\times N}$ is a tridiagonal matrix

$$
\mathbf{T}=\begin{bmatrix}
    2(1+\lambda^2) & -\lambda^2 & 0 & \cdots & 0\\
    -\lambda^2 & 2(1+\lambda^2) & -\lambda^2 & \cdots & 0\\
    0 & -\lambda^2 & 2(1+\lambda^2) & \cdots & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \cdots & 2(1+\lambda^2)
\end{bmatrix}.
$$

$\mathbf{b}\in\R^{(N+1)M}$ is a vector

$$
\mathbf{b}=[-2kg_1,\cdots,-2kg_N,0,\cdots,0]^\top.
$$

It is obvious that $\mathbf{A}$ is not symmetric. 

### Question (b)

Use second ordered forward difference at $j=0$ to handle the bottom boundary condition

$$
\frac{1}{k}(-\frac{3}{2}u_{i,0}+2u_{i,1}-\frac{1}{2}u_{i,2})=g_i\implies u_{i,0}=\frac{4}{3}u_{i,1}-\frac{1}{3}u_{i,2}-\frac{2}{3}kg_i,
$$

and (6.17) at $j=1$ becomes

$$
-\lambda^2 u_{i+1,1}+2(1+\lambda^2)u_{i,1}-\lambda^2 u_{i-1,1}-u_{i,2}-\frac{4}{3}u_{i,1}+\frac{1}{3}u_{i,2}+\frac{2}{3}kg_i=0.
$$

That is 

$$
-\lambda^2 u_{i+1,1}+\left(2(1+\lambda^2)-\frac{4}{3}\right)u_{i,1}-\lambda^2 u_{i-1,1}-\frac{2}{3}u_{i,2}=-\frac{2}{3}kg_i.
$$

With

$$
v_l=u_{ij},~l=(j-1)N+i,
$$

we express the above FDE system as

$$
\mathbf{A}\mathbf{v}=\mathbf{b},
$$

where $\mathbf{v}\in\R^{NM}$ is the vectorized form of $u_{ij}$. $\mathbf{A}\in\R^{NM\times NM}$ has the following structure

$$
\mathbf{A}=\begin{bmatrix}
    \mathbf{T}-\frac{4}{3}\mathbf{I} & -\frac{2}{3}\mathbf{I} & \mathbf{0} & \mathbf{0} & \cdots & \mathbf{0}\\
    -\mathbf{I} & \mathbf{T} & -\mathbf{I} & \mathbf{0} & \cdots & \mathbf{0}\\
    \mathbf{0} & -\mathbf{I} & \mathbf{T} & -\mathbf{I} & \cdots & \mathbf{0}\\
    \mathbf{0} & \mathbf{0} & -\mathbf{I} & \mathbf{T} & \cdots & \mathbf{0}\\
    \vdots & \vdots & \vdots & \vdots & \ddots & \vdots\\
    \mathbf{0} & \mathbf{0} & \mathbf{0} & \mathbf{0} & \cdots & \mathbf{T}
\end{bmatrix},
$$

where $\mathbf{T}\in\R^{N\times N}$ is a tridiagonal matrix

$$
\mathbf{T}=\begin{bmatrix}
    2(1+\lambda^2) & -\lambda^2 & 0 & \cdots & 0\\
    -\lambda^2 & 2(1+\lambda^2) & -\lambda^2 & \cdots & 0\\
    0 & -\lambda^2 & 2(1+\lambda^2) & \cdots & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \cdots & 2(1+\lambda^2)
\end{bmatrix}.
$$

It is clear that $\mathbf{A}$ is not symmetric.

## Problem 3

![](https://cdn.duanyll.com/img/20240525164443.png)

![](https://cdn.duanyll.com/img/20240525164454.png)

### Question (a)

```{=latex}
\begin{tikzpicture}[darkstyle/.style={circle,draw,fill=gray!40,minimum size=20}]
  \foreach \x in {0,...,2}
    \foreach \y in {0,...,2} {
      \pgfmathtruncatemacro{\label}{\x - 3 * \y + 7}
      \node [darkstyle] (\x\y) at (1.5*\x,1.5*\y) {$P_{\label}$};
    } 

  \foreach \x in {0,...,2}
    \foreach \y [count=\yi] in {0,1} {
      \draw[<->] (\x\y)--(\x\yi);
      \draw[<->] (\y\x)--(\yi\x);
    }
\end{tikzpicture}
```

It is easy to see that the directed graph of $\mathbf{A}$ forms a grid graph. The grid graph is connected, so the matrix $\mathbf{A}$ is irreducible. 

### Question (b)

The Gershgorin-Taussky theorem states that the eigenvalues of a real symmetric matrix lies in the union of intervals

$$
I_i=[a_{ii}-r_i,a_{ii}+r_i].
$$

For the given matrix $\mathbf{A}$, 

$$
\begin{aligned}
    a_{ii}&=2(1+\lambda^2),\\
    r_i&=\begin{cases}
        \lambda^2+1, & i=1,3,7,9\\
        2\lambda^2+1, & i=2,8\\
        \lambda^2+2, & i=4,6\\
        2\lambda^2+2, & i=5
    \end{cases}
\end{aligned}
$$

Therefore 

$$
\begin{aligned}
    \lambda_L&=\min_i(a_{ii}-r_i)=0,\\
    \lambda_R&=\max_i(a_{ii}+r_i)=4+4\lambda^2.
\end{aligned}
$$


## Problem 4

![](https://cdn.duanyll.com/img/20240525164524.png)

![](https://cdn.duanyll.com/img/20240525164542.png)

### Question (a)

From equation (6.15) we can derive $\tau$ with $u(x_i,y_j)$

$$
-\lambda^2u(x_{i+1},y_j)+2(1+\lambda^2)u(x_i,y_j)-\lambda^2u(x_{i-1},y_j)-u(x_i,t_{j+1})-u(x_i,t_{j-1})=k^2\tau_{ij}.
$$

Substracting the above equation with Equation (6.17)

$$
-\lambda^2u_{i+1,j}+2(1+\lambda^2)u_{ij}-\lambda^2u_{i-1,j}-u_{i,j+1}-u_{i,j-1}=0,
$$

and use the definition of error $e_{ij}=u(x_i,y_j)-u_{ij}$, we have

$$
-\lambda^2e_{i+1,j}+2(1+\lambda^2)e_{ij}-\lambda^2e_{i-1,j}-e_{i,j+1}-e_{i,j-1}=k^2\tau_{ij}.
$$

The above equation has the same coefficient matrix as Equation (6.17). Same simplification can be applied to the boundary conditions, where the left side of the equaiton has the same coefficient matrix, and the constants on the right side are discarded, leaving only $k^2\tau_{ij}$. Therefore the error FDE system can be expressed with the same matrix $\mathbf{A}$ as in (6.21), and the system is 

$$
\mathbf{A}\mathbf{e}=k^2\boldsymbol{\tau}.
$$

### Question (b)

$\mathbf{A}$ is symmetric and positive definite $\implies$ $\mathbf{A}$ is invertible. From the Cauchy-Schwarz inequality, we have

$$
\begin{aligned}
    \|\mathbf{A}^{-1}\boldsymbol{\tau}\|_2&\leq\|\mathbf{A}^{-1}\|_2\cdot\|\boldsymbol{\tau}\|_2,\\
    \frac{1}{k^2}\|\mathbf{e}\|_2&\leq\|\mathbf{A}^{-1}\|_2\cdot\|\boldsymbol{\tau}\|_2,\\
    \|\mathbf{e}\|_2&\leq k^2\|\mathbf{A}^{-1}\|_2\cdot\|\boldsymbol{\tau}\|_2.
\end{aligned}
$$

The Schur inequality states that

$$
\sum_{i=1}^n|\lambda_i|^2\leq\|\mathbf{A}\|_2.
$$

That is

$$
\|\mathbf{A}^{-1}\|_2\geq\sum_{i=1}^n\frac{1}{|\lambda_i|^2}\geq\frac{1}{\lambda_m}.
$$

Therefore

$$
\|\mathbf{e}\|_2\leq k^2\frac{1}{\lambda_m}\|\boldsymbol{\tau}\|_2.
$$

### Question (c)

From Section 6.2.2 we know

$$
\lambda_m=8\sin^2\frac{\pi h}{2}\geq 8h^2=8k^2.
$$

Therefore

$$
\|\mathbf{e}\|_2\leq\frac{1}{8}\|\boldsymbol{\tau}\|_2.
$$

That indicates that the error is bounded by the truncation error.