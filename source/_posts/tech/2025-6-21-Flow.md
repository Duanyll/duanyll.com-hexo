---
title: Flow Matching 与 DDIM 小记
tags:
  - Flow Matching
  - DDIM
  - 生成模型
  - 炼丹
---

## 背景故事

2022 年 10 月左右，同期有三篇关于 Flow 模型用于图像生成的论文发表，并都被 ICLR 2023 录用：

- [Flow Matching for Generative Modeling](https://arxiv.org/abs/2210.02747)
- [Learning to Generate and Transfer Data with Rectified Flow](https://arxiv.org/abs/2209.03003)
- [Building Normalizing Flows with Stochastic Interpolants](https://arxiv.org/pdf/2209.15571)

这三篇文章从不同角度出发得推导出了同一个生成模型，下面再整理一下三篇论文的故事讲法。

### Flow Matching

{% folding 背景：连续归一化流 %}

连续归一化流（Continuous Normalizing Flows, CNF）的概念最早由 [Chen et al. (2018)](https://arxiv.org/abs/1806.07366) 提出，CNF 通过求解常微分方程（ODE）来实现数据的变换。时间依赖的概率密度路径 $p_t(x)$ 满足 $\int p_t(x) \d x = 1$, 流的动态由时间依赖的向量场 $\b{v}_t:[0,1]\times\R^d\to\R^d$ 定义：

$$
\frac{\d}{\d t}\phi_t(\b{x})=\b{v}_t(\phi_t(\b{x}),\quad \phi_0(\b{x})=\b{x}
$$

CNF 可以通过推前操作将先验分布 $p_0$ 转换为目标分布 $p_t$（理论上的结论，并不能用于采样）：

$$
p_t(\b{x}) = p_0(\phi_t^{-1}(\b{x})) \det\left[ \frac{\p \phi_t^{-1}(\b{x})}{\p \b{x}} \right]
$$

同时连续性方程可用于验证向量场 $\b{v}_t$ 是否生成满足以上性质的概率路径：

$$
\frac{\d}{\d t} p_t(\b{x}) + \nabla \cdot (p_t(\b{x}) \b{v}_t(\b{x})) = 0
$$

{% endfolding %}

CNF 可以用于建模任意的概率路径，然而此前不存在高效的方法 [^1]来学习向量场 $\b{v}_t$。Flow Matching 论文提出了条件流匹配方法（Conditional Flow Matching, CFM）实现从数据集中采样学习向量场 $\b{v}_t$。首先引入 Flow Matching 损失函数，用神经网络 $\b{v}_t(\b{x};\theta)$ 来回归近似向量场 $\b{u}_t(\b{x})$：

$$
\mathcal{L}_{\text{FM}}(\theta) = \mathbb{E}_{t,p_t(\b{x})}\left\|\b{v}_t(\b{x};\theta) - \b{u}_t(\b{x})\right\|^2
\label{fmLoss}
$$

[^1]: 关于 CNF 的对数似然求解方法可以参考 CNF 原文。[这篇知乎文章](https://zhuanlan.zhihu.com/p/10764455963) 也有介绍。对数似然训练 Neural ODE 在高维空间效果差且不稳定。

再来进一步考虑如何构造可从数据集中采样求得的 $\b{u}_t$ 和 $p_t(\b{x})$。将数据集中的样本 $\b{x}_1\sim q(\b{x}_1)$ 视作条件，那么 $p_t(\mathbf{x})$ 作为条件概率路径 $p_t(\b{x}|\b{x}_1)$ 的边缘分布可以通过积分得到：

$$
p_t(\b{x}) = \int p_t(\b{x}|\b{x}_1) q(\b{x}_1) \d \b{x}_1
$$

类似的，向量场 $\b{u}_t(\b{x})$ 可以视作条件向量场 $\b{u}_t(\b{x}|\b{x}_1)$ 的边缘分布，通过积分得到:

$$
\b{u}_t(\b{x}) = \int \b{u}_t(\b{x}|\b{x}_1) \frac{p_t(\b{x}|\b{x}_1) q(\b{x}_1)}{p_t(\b{x})} \d \b{x}_1
$$

原文证明了条件向量场 $\b{u}_t(\b{x}|\b{x}_1)$ 确实能生成条件概率密度路径 $p_t(\b{x}|\b{x}_1)$。进一步，论文证明了条件流匹配损失函数

$$
\mathcal{L}_{\text{CFM}}(\theta) = \mathbb{E}_{t,q_(\b{x}_1),p_t(\b{x}|\b{x}_1)}\left\|\b{v}_t(\b{x};\theta) - \b{u}_t(\b{x}|\b{x}_1)\right\|^2
$$

的梯度等价于 FM 损失函数 $(\ref{fmLoss})$ 的梯度，故可以使用 CFM 损失函数训练 CNF 模型。此结论并未依赖于具体的条件概率路径 $p_t(\b{x}|\b{x}_1)$ 或条件向量场 $\b{u}_t(\b{x}|\b{x}_1)$ 的设计。

在图像生成模型中，一般把高斯噪声作为先验分布，即 $p(\b{x})=\mathcal{N}(\b{x};\b{0},\b{I})$。流映射在 $\b{x}_1$ 条件下总是可以写成

$$
\phi_t(\b{x}) = \sigma_t(\b{x}_1)\b{x} + \mu_t(\b{x}_1)
$$

可以证明此时的条件速度场具有唯一的形式

$$
\b{u}_t(\b{x}|\b{x}_1) = \frac{\sigma_t'(\b{x}_1)}{\sigma_t(\b{x}_1)}(\b{x} - \mu_t(\b{x}_1)) + \mu_t'(\b{x}_1)
$$

DDIM 的均值 $\mu_t(\b{x}_1)=\alpha_{1-t}\b{x}_1$ 和方差 $\sigma_t(\b{x}_1)=\sqrt{1-\alpha_{1-t}^2}$ 可以直接带入到上式中，得到 Flow Matching 框架下的条件速度场。

论文又提出 OT 速度场的设计，使用线性插值的均值 $\mu_t(\b{x}_1)=t\b{x}_1$ 和方差 $\sigma_t(\b{x}_1)=1-(1-\sigma_{\text{min}})t$。通过实验发现 OT 速度场训练收敛更快且 FID 更低。

### Rectified Flow

{% folding 背景：传输映射问题 %}

给定 $\R^d$ 上两个可以观测的分布 $\pi_0,\pi_1$，目标是寻找传输映射 $T:\R^d\to\R^d$ 将 $Z_0\sim\pi_0$ 映射到 $Z_1=T(Z_0)\sim\pi_1$。

在生成建模中，$\pi_1$ 是未知但可观测目标分布（图像数据集），而 $\pi_0$ 是简单的先验分布（如高斯分布）。还可以考虑传输建模，即 $\pi_0$ 和 $\pi_1$ 都是未知的可观测分布。

最优传输（Optimal Transport, OT）目标希望最小化某个代价函数 $c:\R^d\to\R$，即

$$
\min_{T} \mathbb{E}\left[c(T(Z_0)-Z_0)\right]
$$

其中 $c$ 可以是 L2 范数或则其他度量。一般的 OT 问题非常难解，在图像生成任务中也不太关心最小化代价。Rectified Flow 和 Reflow 是此背景下一种实用的近似方法。

{% endfolding %}

Rectified Flow 使用一个简单的 ODE 来学习传输映射 $T$。从 $Z_0\sim\pi_0$ 出发，沿速度场 $v:\R^d\times[0,1]\to\R^d$ 进行演化，得到 $Z_1\sim\pi_1$：

$$
\d Z_t = v_t(Z_t)\d t,\quad t\in[0,1],Z_0\sim\pi_0
\label{rfOde}
$$

问题转换为学习速度场 $v$。直观的想法（先前的工作）是想最小化 ODE 采样结果 $Z_1$ 的分布 $\rho_1^v$ 和目标分布 $\pi_1$ 的距离 $D(\rho_1^v,\pi_1)$，如 KL 散度，但多次模拟求解 ODE 的代价太高了。发现此问题中，速度场 $v$ 实际上是过参数化的：我们只关心开头和结尾的分布应当是 $\pi_0$ 和 $\pi_1$，而中间的分布并不重要，可以人为地设置非常强的先验。简单的选择是让中间分布是开头结尾的某种线性插值，走直线路径，这样不仅能更接近 OT 目标，还能减少 ODE 的求解次数。

对源分布和目标分布中观测到的样本 $X_0\sim\pi_0$ 和 $X_1\sim\pi_1$，定义线性插值

$$
X_t = (1-t)X_0 + tX_1,\quad t\in[0,1]
$$

则 $X_t$ 满足以下 ODE：

$$
\d X_t = (X_1-X_0)\d t
$$

还不能直接用这个 ODE 作为速度场 $v$，因为它不是因果的，$X_t$ 依赖于最终状态 $X_1$。论文提出 Rectify 过程来因果化速度场 $v$。思路如下：

![Rectify 过程的 Rewire 特点](https://img.duanyll.com/img/97c80806.png)

1. 不同的插值轨迹 $\{X_t\}$ 之间可能存在相交点，在同一个 $X_t$ 处会有多个可能的 $\dot{X}_t$ 取值，因为不知道要沿哪条轨迹走。
2. 另一方面，在 ODE $(\ref{rfOde})$ 中，$\dot{Z}_t$ 必须由 $Z_t$ 唯一确定，于是不同的 $\{Z_t\}$ 轨迹是不能相交的。
3. 于是在相交点处，$v_t(X_t)$ 可以取值为 $\dot{X}_t$ 在所有可能的 $\dot{X}_t$ 取值上的平均值。
   $$
   v_t^*(X_t)=\mathbb{E}[\dot{X}_t|X_t]
   $$
4. 导致原本的直线轨迹 $\{X_t\}$ 必须在相交点处弯曲来避免相交，并改变原分布和目标分布的映射关系。

以上 Rectify 过程更新了传输映射 $T$，但可证明保持了边缘分布 $\pi_0$ 和 $\pi_1$ 不变。训练目标为

$$
\min_v\int_0^1\mathbb{E}\left[\left\|\dot{X}_t-v_t(X_t)\right\|^2\right]\d t
$$

代入线性插值轨迹得到训练目标

$$
\min_v\int_0^1\mathbb{E}\left[\left\|X_1-X_0-v_t((1-t)X_0+tX_1)\right\|^2\right]\d t
$$

> 此训练目标就可以直接用在代码里了。

Rectify 过程将 $\{X_t\}$ 轨迹转换为因果的 $\{Z_t\}$ 轨迹，不仅保持边缘分布不变，还可以证明对于凸的代价函数 $c$，传输代价不增

$$
\mathbb{E}[c(Z_1-Z_0)]\leq\mathbb{E}[c(X_1-X_0)]
$$

{% folding Reflow %}

![Reflow 拉直轨迹](https://img.duanyll.com/img/5856eba6.png)

原本 $\{X_t\}$ 轨迹是直的，经过 Rectify 过程后 $\{Z_t\}$ 会在相交点弯曲，起不到一开始选择线性插值轨迹时，保持直线的优势。论文提出 Reflow 过程来修正这个问题，使用 Rectify 过程得到的 $\{Z_0,Z_1\}$ 配对耦合重新训练速度场 $v$ 并反复迭代：

$$
\{Z_t^{k+1}\}=\operatorname{Rectify}(\operatorname{Interp}(Z_0^k,Z_1^k))
$$

论文证明了对于下面的 “直线程度” 度量

$$
S(\{Z_t\})=\int_0^1\mathbb{E}\left[\left\|Z_1-Z_0-\dot{Z}_t\right\|^2\right]\d t
$$

满足

$$
\mathbb{E}_{k\in\operatorname{Uniform}\{1,\cdots,K\}}[S(\{Z_t^k\})]=\mathcal{O}(1/K)
$$

随 $k\to+\infty$ 收敛到 0。也就是说，经过 Reflow 过程后，$\{Z_t\}$ 轨迹会越来越接近直线。

Reflow 其实就是从 OT 角度解释了先前的时间步蒸馏技巧。常见的预训练模型都没有做 Reflow 蒸馏。

{% endfolding %}

### Stochastic Interpolants

WIP.

### Diffusion

DDPM 和 DDIM 也有很多种推导的方法，下面摘自 [苏神博客](https://spaces.ac.cn/archives/9164) 中贝叶斯角度的推导，比较接近 DDIM 论文的推导方式。

#### DDPM

与 GAN 类似，DDPM 模型将生成定义为将一个随机噪声 $z$ 变换成真实图像 $x$ 的过程。然而，像 GAN 一样一步将噪声映射到真实图像的分布是困难的，因此 DDPM 考虑逐步地将噪声 $z$ 变换为真实图像。首先定义一个前向过程，即将真实图像样本 $x$ 逐步添加噪声，直到完全成为高斯噪声，则生成图像的过程即为将噪声 $z$ 逐步变为样本数据的反向过程。前向过程的每个步骤可以表示为

$$
    x_t = \alpha_tx_{t-1} + \beta_t\epsilon_t,\quad\epsilon_t\sim\mathcal{N}(0, I),\quad t=1,2,\cdots,T,
$$

其中 $x_0=x$ 是真实图像样本数据，$x_T=z$ 是完全随机的高斯噪声，$T$ 是设置的时间步数。$\{\alpha_t\}$ 和 $\{\beta_t\}$ 是控制每一步添加噪声强度的系数。前向过程也可以写成条件概率分布的形式

$$
    p(x_t|x_{t-1}) \sim \mathcal{N}(x_t;\alpha_tx_{t-1}, \beta_t^2I),
    \label{eq:pxtxtm1}
$$

其中 $p(x_t|x_{t-1})$ 代表在前向过程中 $x_{t-1}$ 到 $x_t$ 的条件概率分布。

注意到如果规定 $\alpha_t^2+\beta_t^2=1$，则可以从 $x_0$ 直接推导出 $x_t$

$$
    \begin{aligned}
        x_t &= \alpha_tx_{t-1} + \beta_t\epsilon_t \\
            &= \alpha_t(\alpha_{t-1}x_{t-2} + \beta_{t-1}\epsilon_{t-1}) + \beta_t\epsilon_t \\
            &= \left(\prod_{i=1}^t\alpha_i\right)x_0 + \sum_{i=1}^t\left(\prod_{j=i+1}^t\alpha_j\right)\beta_i\epsilon_i,
    \end{aligned}
$$

于是 $x_t$ 中包含 $t$ 个独立的高斯噪声 $\epsilon_i$ 的线性组合。代入 $\alpha_t^2+\beta_t^2=1$ 的条件，得到

$$
\prod_{i=1}^t\alpha_i^2+\sum_{i=1}^t\left(\prod_{j=i+1}^t\alpha_j\right)^2\beta_i^2=1.
$$

将 $\prod_{i=1}^t\alpha_i$ 记为 $\bar{\alpha_t}$，$\sqrt{1-\prod_{i=1}^t\alpha_i}$ 记为 $\bar{\beta_t}$\footnote{本论文中为了符号的一致性，$\bar{\alpha}_t$ 的定义与 DDPM 论文并不相同。}，则 $x_t$ 关于 $x_0$ 的条件概率分布为

$$
    p(x_t|x_0)=\mathcal{N}(x_t;\bar{\alpha_t}x_0, \bar{\beta_t}^2I),
    \label{eq:pxtx0}
$$

也可以写成

$$
    x_t = \bar{\alpha_t}x_0 + \bar{\beta_t}\bar{\epsilon}_t,\quad\bar{\epsilon}_t\sim\mathcal{N}(0, I).
    \label{eq:xtx0e}
$$

只要 $\lim_{t\to\infty}\bar{\alpha_t}=0$，经过充分多的时间步后，$x_t$ 就会足够接近标准高斯分布 $\mathcal{N}(0, I)$。利用 $(\ref{eq:pxtx0})$，可以快速从 $x_0$ 采样到 $x_t$。接下来考虑反向过程，关键在于求条件概率分布 $p(x_{t-1}|x_t)$ 以便从噪音多的时间步还原噪音少的时间步。根据贝叶斯公式

$$
    p(x_{t-1}|x_t)=\frac{p(x_t|x_{t-1})p(x_{t-1})}{p(x_t)},
$$

然而，$p(x_{t-1})$ 和 $p(x_t)$ 是未知的。考虑引入 $x_0$ 作为条件变量，则

$$
    p(x_{t-1}|x_t,x_0)=\frac{p(x_t|x_{t-1})p(x_{t-1}|x_0)}{p(x_t|x_0)}.
    \label{eq:ddpm-bayes}
$$

代入 $(\ref{eq:pxtxtm1})$ 和 $(\ref{eq:pxtx0})$，可以写出 $p(x_{t-1}|x_t,x_0)$ 服从的分布

$$
    p(x_{t-1}|x_t,x_0) \sim \mathcal{N}\left(
        x_{t-1};
        \frac{\alpha_t\bar{\beta}^2_{t-1}}{\bar{\beta}^2_t}x_t
        +\frac{\bar{\alpha}_{t-1}\beta_t^2}{\bar{\beta}_t^2}x_0,
        \frac{\bar{\beta}_{t-1}^2\beta_t^2}{\bar{\beta}_t^2}I
    \right),
    \label{eq:ddpm-bayes-sol}
$$

使用此分布采样 $x_{t-1}$ 需要已知 $x_0$，然而 $x_0$ 正是最终要生成的图像。DDPM 引入可学习的函数 $\bar{\mu}(x_t)$ 来近似估计未知的 $x_0$，训练的目标为最小化损失函数 $\|x_0-\bar{\mu}(x_t)\|^2$。DDPM 实际上没有使用神经网络 $\varepsilon_\theta(x_t,t)$ 直接预测原始图像 $x_0$，而是用于预测添加的噪声 $\bar{\epsilon}_t$，这样在每一步上神经网络的输出都服从标准高斯分布，有助于提高训练的稳定性。根据 $(\ref{eq:xtx0e})$，可以重参数化 $\bar{\mu}(x_t)$ 为

$$
    \bar{\mu}(x_t) = \frac{1}{\bar{\alpha}_t}(x_t-\bar{\beta}_t\varepsilon\theta(x_t,t)),
    \label{eq:muxt}
$$

进而得到完整的损失函数

$$
    \mathcal{L}(\theta) = \mathbb{E}_{t,x_0,\epsilon_t}\left\|
        \epsilon_t-\varepsilon_\theta(\bar{\alpha}_t x_0 + \bar{\beta}_t\epsilon_t,t)
    \right\|^2.
    \label{eq:ddpm-loss}
$$

最后，用 $(\ref{eq:muxt})$ 近似 $x_0$ 代入 $(\ref{eq:ddpm-bayes-sol})$，得到与 $x_0$ 无关的反向过程条件概率分布

$$
    p(x_{t-1}|x_t) \sim \mathcal{N}\left(
        x_{t-1};
        \frac{1}{\alpha_t}\left(
            x_t-\frac{\beta_t^2}{\bar{\beta}_t}\varepsilon_\theta(x_t,t)
        \right),
        \frac{\bar{\beta}_{t-1}^2\beta_t^2}{\bar{\beta}_t^2}I
    \right),
$$

并进一步得到 DDPM 的迭代采样公式

$$
    x_{t-1} = \frac{1}{\alpha_t}\left(
        x_t-\frac{\beta_t^2}{\bar{\beta}_t}\varepsilon_\theta(x_t,t)
    \right)+\sigma_t\epsilon,\quad\epsilon\sim\mathcal{N}(0, I),
    \label{eq:ddpm-step}
$$

其中 $\sigma_t=\bar{\beta}_{t-1}\beta_t/\bar{\beta}_t$，$t=1,\cdots,T$。

在 DDPM 原始的实验中，$T$ 取值为 1000，$\alpha_t$ 根据经验设置为 $\alpha_t=\sqrt{1-\frac{0.02t}{T}}$. 观察 $(\ref{eq:ddpm-step})$，可以发现每一步的采样都需要计算神经网络 $\varepsilon_\theta(x_t,t)$，因此计算量非常大。同时 DDPM 的每一步采样都包括对随机噪声 $\epsilon$ 的采样，结果具有不确定性。

#### DDIM

DDIM（Denoising Diffusion Implicit Models）模型在 DDPM 的基础上进一步推导了采样公式，发展了允许跳过时间步和确定性的采样方法，并允许将扩散模型的采样过程与常微分方程和随机微分方程的求解算法结合起来。本节将介绍 DDIM 的主要推导过程和结论。

注意到在 DDPM 的神经网络 $\varepsilon_\theta(x_t,t)$ 的训练过程 $(\ref{eq:ddpm-loss})$ 中，只依赖了关于 $p(x_t|x_0)$ 的假定 $(\ref{eq:pxtx0})$，而与具体的 $p(x_t|x_{t-1})$ 的设置 $(\ref{eq:pxtxtm1})$ 无关，因此在求解贝叶斯公式 $(\ref{eq:ddpm-bayes})$ 时，不再代入 $p(x_t|x_{t-1})$，而是假设 $p(x_{t-1}|x_t,x_0)$ 服从高斯分布

$$
    p(x_{t-1}|x_t,x_0) \sim \mathcal{N}(x_{t-1};\kappa_t x_t+\lambda_t x_0, \sigma^2_t I),
$$

则关于 $x_{t-1}$ 的采样公式可以写成

$$
    \begin{aligned}
        x_{t-1} &= \kappa_t x_t + \lambda_t x_0 + \sigma_t\epsilon \\
                &= \kappa_t(\bar{\alpha}_t x_0+\bar{\beta}_t\epsilon_1) + \lambda_t x_0 + \sigma_t\epsilon_2 \\
                &= (\kappa_t\bar{\alpha}_t+\lambda_t)x_0 + \kappa_t\bar{\beta}_t\epsilon_1 + \sigma_t\epsilon_2 \\
                &= (\kappa_t\bar{\alpha}_t+\lambda_t)x_0 + \sqrt{\kappa_t\bar{\beta}_t^2+\sigma^2_t}\epsilon.
    \end{aligned}
$$

比较上式与 $(\ref{eq:xtx0e})$ 的系数，消去 $\kappa_t$ 和 $\lambda_t$，得到

$$
    p(x_{t-1}|x_t,x_0) \sim \mathcal{N}\left(
        x_{t-1};
        \frac{\sqrt{\bar{\beta}^2_{t-1}-\sigma_t^2}}{\bar{\beta}_t}x_t
        +\left(\bar{\alpha}_{t-1}-\bar{\alpha}_t\frac{\sqrt{\bar{\beta}^2_{t-1}-\sigma_t^2}}{\bar{\beta}_t}\right)x_0,
        \sigma^2_t I
    \right),
    \label{eq:ddim-bayes-sol}
$$

是关于 $p(x_{t-1}|x_t,x_0)$ 服从的分布的通解，具有自由参数 $\sigma_t$. 沿用 DDPM 训练的神经网络模型，用 $(\ref{eq:muxt})$ 近似 $x_0$ 代入 $(\ref{eq:ddim-bayes-sol})$，得到 DDIM 的迭代采样公式

$$
    x_{t-1} = \frac{x_t-\bar{\beta}_t\varepsilon_\theta(x_t,t)}{\alpha_t}
            + \sqrt{\bar{\beta}^2_{t-1}-\sigma^2_t}\varepsilon_\theta(x_t,t)
            + \sigma_t\epsilon,\quad\epsilon\sim\mathcal{N}(0, I),
    \label{eq:ddim-step}
$$

公式中的三项可分别视作从 $x_t$ 预测的 $x_0$，从当前步指向 $x_t$ 的方向和随机噪声。注意到 $\sigma_t$ 是可自由选取的超参数，当 $\sigma_t=0$ 时，$(\ref{eq:ddim-step})$ 变为确定性的采样方式

$$
    x_{t-1} = \frac{x_t-\bar{\beta}_t\varepsilon_\theta(x_t,t)}{\alpha_t}
            + \bar{\beta}_{t-1}\varepsilon_\theta(x_t,t).
$$

另外，在推导 $(\ref{eq:ddim-step})$ 的过程中并不依赖于 $p(x_{t-1}|x_t,x_0)$，同样的过程也适用于推导任意两个时间步 $t$ 和 $t'$ 之间的采样公式

$$
    x_{t'} = \frac{\bar{\alpha}_{t'}(x_t-\bar{\beta}_t\varepsilon_\theta(x_t,t))}{\bar{\alpha}_t}
            + \sqrt{\bar{\beta}^2_{t'}-\sigma^2_t}\varepsilon_\theta(x_t,t)
            + \sigma_t\epsilon,\quad\epsilon\sim\mathcal{N}(0, I),
$$

这实质上允许了以任意的时间步序列 $\{\tau_i\}$ 进行采样，不仅可以跳过时间步节约计算量，还允许确定性地从图像样本 $x_0$ 完全或者部分地反推对应的带噪声图像 $x_t$，为带参考图像作为条件的图像生成和编辑提供了注入参考图像信息的方法，称为 DDIM 反转。$(\ref{eq:ddim-step})$ 也可以视作使用欧拉法求解常微分方程，可以推导出对应的常微分方程形式或者随机微分方程的形式，然后使用 Heun 法、Runge-Kutta 法等效率更高的数值求解方法进行采样。

## Flow 与 DDIM 联系

三篇提出 Flow 模型的论文都分析了 DDIM 模型在 Flow 框架中的地位。在 FM 论文中，可以使用 DDIM 的均值和方差特性来设计条件速度场 $\b{u}_t(\b{x}|\b{x}_1)$，从而得到 Flow Matching 的条件流匹配损失函数 $\mathcal{L}_{\text{CFM}}$。在 Rectified Flow 框架和 Stochastic Interpolants 框架中，DDIM 相当于使用球面插值取代了线性插值，并应用了时间步缩放。

后续有一些博客文章整理和可视化了 Flow Matching 和 DDIM 的关系：

- [Diffusion Meets Flow Matching](https://diffusionflow.github.io/) - DeepMind
- [Let us Flow Together](https://rectifiedflow.github.io/) - UT Austin

Flow 和 Diffusion 的关系可以从重参数化、插值方式和 ODE/SDE 的角度来讨论。

### 重参数化

此处重参数化指的是在模型中神经网络预测的对象不一样。DDIM 采样公式可以写成以下简单形式：

$$
Z_s = \alpha_s\hat{X}+\sigma_s\hat{\epsilon},\quad \hat{X}=\frac{Z_t-\sigma_t\hat{\epsilon}}{\alpha_t}
$$

其中 $\hat{X}$ 是从当前步对最终干净图像的预测，$\hat{\epsilon}$ 是当前步对噪声的预测。一般 Diffusion 模型中神经网络预测的是 $\hat{\epsilon}$，也可以选择预测 $\hat{X}$。

Flow 模型的采样公式为

$$
Z_s = Z_t + \hat{u} \cdot (s-t)
$$

神经网络预测速度场 $\hat{u}$。于是发现无论神经网络预测的是 $\hat{X}$，$\hat{\epsilon}$ 还是 $\hat{u}$，采样公式都可以统一地写成

$$
\tilde{Z}_s = \tilde{Z}_t + \phi(Z_t,t)\cdot(\eta_s-\eta_t)
$$

其中 $\phi$ 是神经网络，$\tilde{Z}_t$ 和 $\eta_t$ 是

| $\phi$           | $\tilde{Z}_t$             | $\eta_t$                       |
| ---------------- | ------------------------- | ------------------------------ |
| $\hat{X}$        | $Z_t/\sigma_t$            | $\alpha_t/\sigma_t$            |
| $\hat{\epsilon}$ | $Z_t/\alpha_t$            | $\sigma_t/\alpha_t$            |
| $\hat{v}$        | $Z_t/(\alpha_t+\sigma_t)$ | $\sigma_t/(\alpha_t+\sigma_t)$ |
| $\hat{u}$        | $Z_t$                     | $t$                            |

表中 $\hat{v}$ 指一般的 Flow Matching 模型，$\hat{u}$ 特指 Rectified Flow 模型的线性插值速度场。

> 此处跳过 DeepMind 博客中关于采样时重参数化和缩放的讨论，在下一小节讨论插值时会提到。

考虑重参数化对训练过程的影响。常用的 DDIM 的损失函数为

$$
\mathcal{L}_{\text{DDIM}} = \mathbb{E}_{t,x,\epsilon}\left[w(\lambda_t)\cdot\frac{\d\lambda}{\d t}\cdot\|\hat{\epsilon}-\epsilon\|^2\right],\quad\lambda_t=\ln\frac{\alpha_t^2}{\sigma_t^2}
$$

其中 $\lambda_t$ 是对数信噪比，$w(\lambda_t)$ 是人为选定的时间步权重函数。

在 Stable Diffusion 3 中，CFM 训练的损失函数中也引入了人为选择的时间步权重函数：

$$
\mathcal{L}_{\text{SD3}} = \mathbb{E}_{t,x,\epsilon}\left[w(\lambda_t)\cdot\|\hat{u}-u\|^2\right]
$$

为了便于比较，我们把这些损失函数都重参数化使用 $\hat{\epsilon}$ 来表达

| $\phi$                                           |                                                 $\mathcal{L}$ | 说明                                           |
| :----------------------------------------------- | ------------------------------------------------------------: | ---------------------------------------------- |
| $\hat{\epsilon}$                                 |                               $\|\hat{\epsilon}-\epsilon\|^2$ | 放大 $\lambda$ 小时 $\epsilon$ 的误差          |
| $\hat{X}=(Z_t-\sigma_t\hat{\epsilon})/\alpha_t$  |                 $e^{-\lambda_t}\|\hat{\epsilon}-\epsilon\|^2$ | 放大 $\lambda$ 大时 $\epsilon$ 的误差          |
| $\hat{v}=\alpha_t\hat{\epsilon}-\sigma_t\hat{X}$ | $\alpha_t^2(e^{-\lambda_t}+1)^2\|\hat{\epsilon}-\epsilon\|^2$ |
| $\hat{u}=\hat{\epsilon}-\hat{X}$                 |           $(e^{-\lambda/2}+1)^2\|\hat{\epsilon}-\epsilon\|^2$ | 重点关注中间时间步，忽略过大或过小的 $\lambda$ |

表明神经网络的不同预测对象意味着在预测 $\hat{\epsilon}$ 的基础上，对损失函数施加了不同的时间步权重。

![不同模型中等效的时间步权重](https://img.duanyll.com/img/bff8ac8e.png)

结合考虑重参数化的影响，SD3 的损失函数时间步权重实际上很接近 EDM.

### 插值

### ODE / SDE
